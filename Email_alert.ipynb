{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54427f26-8be8-4bf0-8f01-7185909f9d71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3477860330566271>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Retrieve the parameters passed from the downstream_audit notebook\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mid\u001B[39m \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      3\u001B[0m data_team_email \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData_Team_email\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m data_team_password \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData_Team_password\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/WidgetHandlerImpl.py:77\u001B[0m, in \u001B[0;36mWidgetsHandlerImpl.get\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n",
       "\u001B[1;32m     38\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Returns the current value of a widget with the given name.\u001B[39;00m\n",
       "\u001B[1;32m     39\u001B[0m \n",
       "\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    :param name: Name of the argument to be accessed\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m        ```\u001B[39;00m\n",
       "\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m---> 77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_notebookArguments\u001B[38;5;241m.\u001B[39mgetArgument(name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_entry_point\u001B[38;5;241m.\u001B[39mgetCurrentBindings())\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:255\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpy4j\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotocol\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Py4JJavaError\n",
       "\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
       "\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    257\u001B[0m     converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o424.getArgument.\n",
       ": com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named id is defined\n",
       "\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n",
       "\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:264)\n",
       "\tat sun.reflect.GeneratedMethodAccessor854.invoke(Unknown Source)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Py4JJavaError",
        "evalue": "An error occurred while calling o424.getArgument.\n: com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named id is defined\n\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:264)\n\tat sun.reflect.GeneratedMethodAccessor854.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>Py4JJavaError</span>: An error occurred while calling o424.getArgument.\n: com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named id is defined\n\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:264)\n\tat sun.reflect.GeneratedMethodAccessor854.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
        "File \u001B[0;32m<command-3477860330566271>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Retrieve the parameters passed from the downstream_audit notebook\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mid\u001B[39m \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m data_team_email \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData_Team_email\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m data_team_password \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData_Team_password\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/WidgetHandlerImpl.py:77\u001B[0m, in \u001B[0;36mWidgetsHandlerImpl.get\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[1;32m     38\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Returns the current value of a widget with the given name.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    :param name: Name of the argument to be accessed\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m        ```\u001B[39;00m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_notebookArguments\u001B[38;5;241m.\u001B[39mgetArgument(name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_entry_point\u001B[38;5;241m.\u001B[39mgetCurrentBindings())\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:255\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpy4j\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotocol\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Py4JJavaError\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
        "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o424.getArgument.\n: com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named id is defined\n\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:264)\n\tat sun.reflect.GeneratedMethodAccessor854.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve the parameters passed from the downstream_audit notebook\n",
    "id = dbutils.widgets.get(\"id\")\n",
    "data_team_email = dbutils.widgets.get(\"Data_Team_email\")\n",
    "data_team_password = dbutils.widgets.get(\"Data_Team_password\")\n",
    "Schema_registry_details=dbutils.widgets.get(\"Schema_registry_details\")\n",
    "print(id)\n",
    "\n",
    "# Convert id from string to integer\n",
    "id = int(id)\n",
    "\n",
    "# Query the downstream_audit table\n",
    "df = spark.sql(f\"select * from ds_training_1.default.downstream_audit where id={id}\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de08da26-2f98-4038-84ee-33508bb799fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Use the correct column name\n",
    "source_table = df.select(\"source_table\").collect()[0][0]\n",
    "table_owner = df.select(\"table_owner\").collect()[0][0]\n",
    "upstream_changed_schema_info=json.loads(df.select(\"upstream_changed_schema_info\").collect()[0][0])\n",
    "TablesInfo=json.loads(df.select(\"TablesInfo\").collect()[0][0])\n",
    "PermissionInfo=json.loads(df.select(\"PermissionInfo\").collect()[0][0])\n",
    "GroupInfo=json.loads(df.select(\"GroupInfo\").collect()[0][0])\n",
    "JobInfo=json.loads(df.select(\"JobInfo\").collect()[0][0])\n",
    "NotebookInfo=json.loads(df.select(\"NotebookInfo\").collect()[0][0])\n",
    "DashboardInfo=json.loads(df.select(\"DashboardInfo\").collect()[0][0])\n",
    "QueryInfo=json.loads(df.select(\"QueryInfo\").collect()[0][0])\n",
    "PipelineInfo=json.loads(df.select(\"pipelineInfo\").collect()[0][0])\n",
    "ModelsInfo=json.loads(df.select(\"ModelsInfo\").collect()[0][0])\n",
    "FileInfo=json.loads(df.select(\"FileInfo\").collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c0cfee-8d28-4ea9-a6f9-e22d088d9c90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from pyspark.sql import functions as F\n",
    "from email.mime.text import MIMEText\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SMTP server configuration\n",
    "smtp_server = \"smtp.gmail.com\"  \n",
    "smtp_port = 587  \n",
    "# smtp_user = \"danduprolu.stuthi@latentview.com\"  \n",
    "# smtp_password = \"ippr iwgm aqji ddlw\"  \n",
    "smtp_user = data_team_email\n",
    "smtp_password = data_team_password\n",
    "# Function to send email notifications\n",
    "def send_email(to_email, subject, body):\n",
    "    try:\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = smtp_user\n",
    "        msg['To'] = to_email\n",
    "        msg['Subject'] = subject\n",
    "        msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "        with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "            server.starttls()\n",
    "            server.login(smtp_user, smtp_password)\n",
    "            server.send_message(msg)\n",
    "        print(f\"Email sent successfully to {to_email}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send email to {to_email}: {e}\")\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SchemaRegistryUpdate\").getOrCreate()\n",
    "\n",
    "def update_schema_registry_table(id):\n",
    "    try:\n",
    "        # Construct the SQL query to update the table (non-Delta version)\n",
    "        update_query = (\n",
    "            f\"UPDATE {Schema_registry_details} \"\n",
    "            f\"SET schema_change_alert_status = 'Notified' \"\n",
    "            f\"WHERE id = '{id}' \"\n",
    "        )\n",
    "        \n",
    "        # Execute the update query using Spark SQL\n",
    "        print(id)\n",
    "        spark.sql(update_query)\n",
    "        \n",
    "        print(f\"Updated the schema registry table {Schema_registry_details} successfully!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to update the schema registry table: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f61fb4b6-e446-4904-89f1-a35867a39d7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def notify_owner(source_table, table_owner, upstream_changes):\n",
    "    # Construct the message for the owner\n",
    "    body = (\n",
    "        f\"Dear {table_owner},\\n\\n\"\n",
    "        f\"The following upstream changes have been made to the table '{source_table}':\\n\\n\"\n",
    "    )\n",
    "\n",
    "    for change in upstream_changes:\n",
    "        body += (\n",
    "            f\"- Schema Version: {change['schema_version']}\\n\"\n",
    "            f\"- Modified By: {change['modified_by']}\\n\"\n",
    "            f\"- Modified Timestamp: {change['modified_timestamp']}\\n\"\n",
    "            f\"- Change Type: {change['change_type']}\\n\"\n",
    "            f\"- Column Name: {change['column_name'] if change['column_name'] else 'N/A'}\\n\"\n",
    "            f\"- Schema JSON: {change['schema_json'] if change['schema_json'] else 'N/A'}\\n\"\n",
    "            f\"- Schema Name: {change['schema_name']}\\n\"\n",
    "            f\"- Created By: {change['created_by']}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    body += \"Please review these changes to ensure your downstream processes remain unaffected.\\n\\nBest regards,\\nYour Data Team\"\n",
    "\n",
    "    # Send the email to the owner\n",
    "    send_email(table_owner, f\"Upstream Changes Notification for {source_table}\", body)\n",
    "\n",
    "    return body  # Return the constructed message for later use\n",
    "\n",
    "def details(source_table, table_owner, upstream_changes):\n",
    "    body = (\n",
    "        f\"The following upstream changes have been made to the table '{source_table}':\\n\\n\"\n",
    "    )\n",
    "    for change in upstream_changes:\n",
    "        body += (\n",
    "            f\"- Schema Version: {change['schema_version']}\\n\"\n",
    "            f\"- Modified By: {change['modified_by']}\\n\"\n",
    "            f\"- Modified Timestamp: {change['modified_timestamp']}\\n\"\n",
    "            f\"- Change Type: {change['change_type']}\\n\"\n",
    "            f\"- Column Name: {change['column_name'] if change['column_name'] else 'N/A'}\\n\"\n",
    "            f\"- Schema JSON: {change['schema_json'] if change['schema_json'] else 'N/A'}\\n\"\n",
    "            f\"- Schema Name: {change['schema_name']}\\n\"\n",
    "            f\"- Created By: {change['created_by']}\\n\\n\"\n",
    "        )\n",
    "    body += \"Please review these changes to ensure your downstream processes remain unaffected.\"\n",
    "    return body \n",
    "\n",
    "def notify_downstream_entities(\n",
    "    source_table, table_owner, upstream_changed_schema_info, TablesInfo, PermissionInfo, \n",
    "    GroupInfo, JobInfo, NotebookInfo, DashboardInfo, QueryInfo, PipelineInfo, ModelsInfo, FileInfo\n",
    "):\n",
    "    # Dictionary to hold email notifications for unique recipients\n",
    "    email_notifications = {}\n",
    "    upstream_changes = []\n",
    "\n",
    "    # Collect all upstream changes for the owner\n",
    "    for upstream in upstream_changed_schema_info:\n",
    "        upstream_changes.append(upstream)\n",
    "\n",
    "    # Notify the owner with all upstream changes at once and get the message\n",
    "    \n",
    "    schema_changes_message=details(source_table, table_owner, upstream_changes)\n",
    "\n",
    "    # Notify for each table in TablesInfo\n",
    "    for table in TablesInfo:\n",
    "        user = table[0]['created_by_email']\n",
    "        table_name = table[0]['name']\n",
    "        catalog_name = table[0]['catalog_name']\n",
    "        schema_name = table[0]['schema_name']\n",
    "\n",
    "        message = (\n",
    "            f\"Your table '{table_name}' in catalog '{catalog_name}' and schema '{schema_name}' has been affected due to recent changes.\\n\\n\"\n",
    "            f\"Details of the upstream change:\\n\"\n",
    "            f\"- Table Name: {table_name}\\n\"\n",
    "            f\"- Catalog Name: {catalog_name}\\n\"\n",
    "            f\"- Schema Name: {schema_name}\\n\\n\"\n",
    "            f\"Please review the changes to ensure your downstream processes remain unaffected.\"\n",
    "        )\n",
    "\n",
    "        if user not in email_notifications:\n",
    "            email_notifications[user] = {'messages': [], 'unique_info': set()}\n",
    "        email_notifications[user]['messages'].append(message)\n",
    "\n",
    "    # Notify based on permissions in PermissionInfo\n",
    "    for perm in PermissionInfo:\n",
    "        principal = perm['Principal']\n",
    "        object_key = perm['ObjectKey']\n",
    "        action_type = perm['ActionType']\n",
    "        email = perm['created_by_email_id']\n",
    "        if '@' in principal:\n",
    "            message = (\n",
    "                f\"You have permissions on the table '{object_key}' which has upstream changes.\\n\\n\"\n",
    "                f\"Action Type: {action_type}\\n\\n\"\n",
    "                f\"Details of the upstream change:\\n\"\n",
    "                f\"- Table Name: {object_key}\\n\\n\"\n",
    "                f\"Please review the changes to ensure your access and operations remain unaffected.\"\n",
    "            )\n",
    "            if email not in email_notifications:\n",
    "                email_notifications[email] = {'messages': [], 'unique_info': set()}\n",
    "            email_notifications[email]['messages'].append(message)\n",
    "\n",
    "    # Notify for each group in GroupInfo\n",
    "    for group in GroupInfo:\n",
    "        previleges = group['Previleges']\n",
    "        ObjectKey = group['ObjectKey']\n",
    "        if group['group_details']:\n",
    "            group_name = group['group_details'][0]['Group Name']\n",
    "            group_id = group['group_details'][0]['Group ID']\n",
    "            email_ids = group['group_details'][0]['Email IDs']\n",
    "        else:\n",
    "            email_ids = []\n",
    "\n",
    "        for member_email in email_ids:\n",
    "            message = (\n",
    "                f\"Your group '{group_name}' has permissions: {previleges} on the table '{ObjectKey}' which is affected by upstream changes.\\n\\n\"\n",
    "                f\"Group Details:\\n\"\n",
    "                f\"- Group ID: {group_id}\\n\\n\"\n",
    "                f\"Please review these changes as they may impact the operations for your group.\"\n",
    " )\n",
    "            if member_email not in email_notifications:\n",
    "                email_notifications[member_email] = {'messages': [], 'unique_info': set()}\n",
    "            email_notifications[member_email]['messages'].append(message)\n",
    "\n",
    "    # Notify for each job in JobInfo\n",
    "    for job in JobInfo:\n",
    "        created_by = job[0]['created_by_email']\n",
    "        entity_name = job[0]['entity_name']\n",
    "        workspace_id = job[0]['workspace_id']\n",
    "        job_id = job[0]['job_id']\n",
    "\n",
    "        message = (\n",
    "            f\"Your job '{entity_name}' may be affected by upstream changes in the source table '{source_table}'.\\n\\n\"\n",
    "            f\"Job Details:\\n\"\n",
    "            f\"- Workspace ID: {workspace_id}\\n\"\n",
    "            f\"- Job ID: {job_id}\\n\\n\"\n",
    "            f\"Please review these changes to assess any impact on the job's operations.\"\n",
    "        )\n",
    "        if created_by not in email_notifications:\n",
    "            email_notifications[created_by] = {'messages': [], 'unique_info': set()}\n",
    "        email_notifications[created_by]['messages'].append(message)\n",
    "\n",
    "    # Notify for each notebook in NotebookInfo\n",
    "    for notebook in NotebookInfo:\n",
    "        created_by = notebook[0]['created_by_email']\n",
    "        workspace_id = notebook[0]['workspace_id']\n",
    "        notebook_id = notebook[0]['notebook_id']\n",
    "\n",
    "        message = (\n",
    "            f\"Your notebook may be affected by upstream changes in the source table '{source_table}'.\\n\\n\"\n",
    "            f\"Notebook Details:\\n\"\n",
    "            f\"- Workspace ID: {workspace_id}\\n\"\n",
    "            f\"- Notebook ID: {notebook_id}\\n\\n\"\n",
    "            f\"Please review these changes to assess any impact on the notebook's functionality.\"\n",
    "        )\n",
    "        if created_by not in email_notifications:\n",
    "            email_notifications[created_by] = {'messages': [], 'unique_info': set()}\n",
    "        email_notifications[created_by]['messages'].append(message)\n",
    "\n",
    "    # Notify for each dashboard in DashboardInfo\n",
    "    for dashboard in DashboardInfo:\n",
    "        created_by = dashboard[0]['created_by_email']\n",
    "        workspace_id = dashboard[0]['workspace_id']\n",
    "        dashboard_id = dashboard[0]['dashboard_id']\n",
    "\n",
    "        message = (\n",
    "            f\"Your dashboard may be affected by upstream changes in the source table '{source_table}'.\\n\\n\"\n",
    "            f\"Dashboard Details:\\n\"\n",
    "            f\"- Workspace ID: {workspace_id}\\n\"\n",
    "            f\"- Dashboard ID: {dashboard_id}\\n\\n\"\n",
    "            f\"Please review these changes to assess any impact on the dashboard's performance.\"\n",
    "        )\n",
    "        if created_by not in email_notifications:\n",
    "            email_notifications[created_by] = {'messages': [], 'unique_info': set()}\n",
    "        email_notifications[created_by]['messages'].append(message)\n",
    "\n",
    "    # Notify for each query in QueryInfo\n",
    "    for query in QueryInfo:\n",
    "        created_by = query[0]['created_by_email']\n",
    "        entity_name = query[0]['entity_name']\n",
    "        workspace_id = query[0]['workspace_id']\n",
    "        query_id = query[0]['query_id']\n",
    "\n",
    "        message = (\n",
    "            f\"Your query '{entity_name}' may be affected by upstream changes in the source table '{source_table}'.\\n\\n\"\n",
    "            f\"Query Details:\\n\"\n",
    "            f\"- Workspace ID: {workspace_id}\\n\"\n",
    "            f\"- Query ID: {query_id}\\n\\n\"\n",
    "            f\"Please review these changes to assess any impact on the query's results.\"\n",
    "        )\n",
    "        if created_by not in email_notifications:\n",
    "            email_notifications[created_by] = {'messages': [], 'unique_info': set()}\n",
    "        email_notifications[created_by]['messages'].append(message)\n",
    "\n",
    "    # Notify for each file in FileInfo\n",
    "    for file in FileInfo:\n",
    "        created_by = file[0]['created_by_email']\n",
    "        workspace_id = file[0]['workspace_id']\n",
    "        file_id = file[0]['file_id']\n",
    "\n",
    "        message = (\n",
    "            f\"Your file may be affected by upstream changes in the source table '{source_table}'.\\n\\n\"\n",
    "            f\"File Details:\\n\"\n",
    "            f\"- Workspace ID: {workspace_id}\\n\"\n",
    "            f\"- File ID: {file_id}\\n\\n\"\n",
    "            f\"Please review these changes to assess any impact on the file's data.\"\n",
    "        )\n",
    "        if created_by not in email_notifications:\n",
    "            email_notifications[created_by] = {'messages': [], 'unique_info': set()}\n",
    "        email_notifications[created_by]['messages'].append(message)\n",
    "    if table_owner not in email_notifications:\n",
    "        owner_message = notify_owner(source_table, table_owner, upstream_changes)\n",
    "\n",
    "    # Send a single email to each unique recipient\n",
    "    for recipient, info in email_notifications.items():\n",
    "        messages = info['messages']\n",
    "        unique_info = info['unique_info']\n",
    "\n",
    "        # Remove duplicate messages\n",
    "        unique_messages = []\n",
    "        for message in messages:\n",
    "            if message not in unique_messages:\n",
    "                unique_messages.append(message)\n",
    "\n",
    "        # Append the upstream changes message\n",
    "        body = (\n",
    "            f\"Dear {recipient},\\n\\n\"\n",
    "            f\"You have been affected by the following upstream changes:\\n\\n\"\n",
    "            f\"{''.join(unique_messages)} \\n\\n\"\n",
    "            f\"{schema_changes_message} \\n\\n\"\n",
    "            f\"Best regards,\\nYour Data Team\"\n",
    "        )\n",
    "        send_email(recipient, f\"Upstream Changes Notification for {source_table}\", body)\n",
    "\n",
    "    print(\"Emails sent to downstream users!\")\n",
    "    for upstream in upstream_changed_schema_info:\n",
    "        update_schema_registry_table(upstream['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcac9a5d-e410-4af6-a19f-8d88152dd68a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully to vishal.kokkula@latentview.com\nEmail sent successfully to danduprolu.stuthi@latentview.com\nEmail sent successfully to kudumalauday.kumarreddy@latentview.com\nEmail sent successfully to brindavivek.kotha@latentview.com\nFailed to send email to N/A: {'N/A': (553, b'5.1.3 The recipient address <N/A> is not a valid RFC 5321 address. For more\\n5.1.3 information, go to\\n5.1.3  https://support.google.com/a/answer/3221692 and review RFC 5321\\n5.1.3 specifications. d75a77b69052e-461452c474fsm27299171cf.93 - gsmtp')}\nEmails sent to downstream users!\n31\nUpdated the schema registry table ds_training_1.default.schema_registry successfully!\n26\nUpdated the schema registry table ds_training_1.default.schema_registry successfully!\n27\nUpdated the schema registry table ds_training_1.default.schema_registry successfully!\n28\nUpdated the schema registry table ds_training_1.default.schema_registry successfully!\n"
     ]
    }
   ],
   "source": [
    "notify_downstream_entities(source_table, table_owner, upstream_changed_schema_info, TablesInfo, PermissionInfo, \n",
    "    GroupInfo, JobInfo, NotebookInfo, DashboardInfo, QueryInfo, PipelineInfo, ModelsInfo, FileInfo)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1184659034704390,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Email_alert",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
